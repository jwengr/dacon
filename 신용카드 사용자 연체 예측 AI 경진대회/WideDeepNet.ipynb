{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL.ipynb",
      "provenance": [],
      "mount_file_id": "1fKrdcd0Z4Nb5vZoV6U7v3mB4fpKnkj-R",
      "authorship_tag": "ABX9TyO7j2Xw+Ahih/DPoz187qmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwengr/dacon/blob/main/%EC%8B%A0%EC%9A%A9%EC%B9%B4%EB%93%9C%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%97%B0%EC%B2%B4%20%EC%98%88%EC%B8%A1%20AI%20%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/WideDeepNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBnxQGUgBZH5"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMSbtbo28cdR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from itertools import combinations\n",
        "from transformers import BertTokenizer\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 564,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxmN0Zja8NMv"
      },
      "source": [
        "PATH = 'drive/My Drive/dacon/credit'"
      ],
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1BAujN_8Zo1"
      },
      "source": [
        "train_df = pd.read_csv(PATH+'/dataset/train.csv').drop(['index','FLAG_MOBIL'],axis=1)\n",
        "test_df = pd.read_csv(PATH+'/dataset/test.csv').drop(['index','FLAG_MOBIL'],axis=1)"
      ],
      "execution_count": 699,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt6KyBMtAAeP"
      },
      "source": [
        "train_df['occyp_type'].fillna('one two three',inplace=True)\n",
        "test_df['occyp_type'].fillna('one two three',inplace=True)"
      ],
      "execution_count": 700,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys-gFWixd1TM"
      },
      "source": [
        "train_df['not_employed'] = (train_df['DAYS_EMPLOYED']>0).astype(np.int32)\n",
        "test_df['not_employed'] = (test_df['DAYS_EMPLOYED']>0).astype(np.int32)"
      ],
      "execution_count": 701,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVvMtMvVe_lf"
      },
      "source": [
        "train_df['begin_months'] = train_df['begin_month'].values%12\n",
        "test_df['begin_months'] = test_df['begin_month'].values%12"
      ],
      "execution_count": 702,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NU92txI8kVW"
      },
      "source": [
        "le = preprocessing.LabelEncoder()"
      ],
      "execution_count": 703,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBC2NrmW9Zmw",
        "outputId": "68212aaa-118b-4ad5-e7f6-6fe4dae35847"
      },
      "source": [
        "for col in ['gender','car','reality','work_phone','phone','email','not_employed','begin_months','family_size']:\n",
        "    train_df[[col]] = le.fit_transform(train_df[[col]]).astype(np.int32)\n",
        "    train_df = pd.concat([train_df,pd.get_dummies(train_df[col],prefix=f'{col}')],axis=1)\n",
        "\n",
        "    test_df[[col]] = le.fit_transform(test_df[[col]]).astype(np.int32)\n",
        "    test_df = pd.concat([test_df,pd.get_dummies(test_df[col],prefix=f'{col}')],axis=1)"
      ],
      "execution_count": 704,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGhXZjxa9s-p"
      },
      "source": [
        "for col in ['income_type','edu_type','family_type','house_type','occyp_type']:\n",
        "    train_df = pd.concat([train_df,pd.get_dummies(train_df[col],prefix=f'{col}')],axis=1)\n",
        "    test_df = pd.concat([test_df,pd.get_dummies(test_df[col],prefix=f'{col}')],axis=1)"
      ],
      "execution_count": 705,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfjU2fIyJQPp"
      },
      "source": [
        "dummies_df = train_df.iloc[:,34:]\n",
        "train_df = train_df.iloc[:,:34]\n",
        "\n",
        "test_dummies_df = pd.DataFrame(columns=dummies_df.columns)\n",
        "for col in test_df.iloc[:,33:].columns:\n",
        "    test_dummies_df[col] = test_df[col]\n",
        "test_dummies_df.fillna(0,inplace=True)\n",
        "test_df = test_df.iloc[:,:33]"
      ],
      "execution_count": 706,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Nq2y8NWYtA"
      },
      "source": [
        "dummies_arr = dummies_df.values\n",
        "test_dummies_arr = test_dummies_df.values"
      ],
      "execution_count": 707,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySlhGRrwVR7r",
        "outputId": "f0ee2928-29ce-4910-b00b-7e66630f1152"
      },
      "source": [
        "dummies_arr.shape,test_dummies_arr.shape"
      ],
      "execution_count": 708,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26457, 62), (10000, 62))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 708
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHKJ3uXPI6hf"
      },
      "source": [
        "wide_arr = np.zeros((len(train_df),dummies_arr.shape[1]*(dummies_arr.shape[1]-1)//2),dtype=np.int32)\n",
        "test_wide_arr = np.zeros((len(test_df),test_dummies_arr.shape[1]*(test_dummies_arr.shape[1]-1)//2),dtype=np.int32)"
      ],
      "execution_count": 709,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ss1ABbqI2P1"
      },
      "source": [
        "i=0\n",
        "for a,b in list(combinations(range(dummies_arr.shape[1]),2)):\n",
        "    wide_arr[:,i] = dummies_arr[:,a]*dummies_arr[:,b]\n",
        "    i+=1\n",
        "i=0\n",
        "for a,b in list(combinations(range(test_dummies_arr.shape[1]),2)):\n",
        "    test_wide_arr[:,i] = test_dummies_arr[:,a]*test_dummies_arr[:,b]\n",
        "    i+=1"
      ],
      "execution_count": 710,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxtHHo7h9t5U"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": 711,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v24NUx_fMmvQ",
        "outputId": "9bbddf8a-503c-4d81-b46f-5eb65ffaa810"
      },
      "source": [
        "print('----train----')\n",
        "for col in ['income_type','edu_type','family_type','house_type','occyp_type']:\n",
        "    print(col,max([len(tokenizer.encode(val)) for val in set(train_df[col].values)]))\n",
        "print('----test----')\n",
        "for col in ['income_type','edu_type','family_type','house_type','occyp_type']:\n",
        "    print(col,max([len(tokenizer.encode(val)) for val in set(test_df[col].values)]))"
      ],
      "execution_count": 712,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----train----\n",
            "income_type 4\n",
            "edu_type 6\n",
            "family_type 6\n",
            "house_type 6\n",
            "occyp_type 8\n",
            "----test----\n",
            "income_type 4\n",
            "edu_type 6\n",
            "family_type 6\n",
            "house_type 6\n",
            "occyp_type 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BFdgqOCCepa"
      },
      "source": [
        "emb_arr = np.zeros((len(train_df),3+5+5+5+7),np.int32)\n",
        "test_emb_arr = np.zeros((len(test_df),3+5+5+5+7),np.int32)"
      ],
      "execution_count": 713,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGZ9CkQjZ1JG"
      },
      "source": [
        "last=0\n",
        "for col,max_length in zip(['income_type','edu_type','family_type','house_type','occyp_type'],[4,6,6,6,8]):\n",
        "    emb_arr[:,last:last+max_length-1] = np.array(train_df[col].apply(lambda x: tokenizer.encode_plus(x,padding='max_length',max_length=max_length)['input_ids'][1:]).values.tolist())\n",
        "    last+=max_length-1\n",
        "last=0\n",
        "for col,max_length in zip(['income_type','edu_type','family_type','house_type','occyp_type'],[4,6,6,6,8]):\n",
        "    test_emb_arr[:,last:last+max_length-1] = np.array(test_df[col].apply(lambda x: tokenizer.encode_plus(x,padding='max_length',max_length=max_length)['input_ids'][1:]).values.tolist())\n",
        "    last+=max_length-1"
      ],
      "execution_count": 714,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ-AlykeapB6"
      },
      "source": [
        "for col in ['income_total','DAYS_BIRTH','DAYS_EMPLOYED','family_size','begin_month']:\n",
        "    scaler = StandardScaler()\n",
        "    train_df[f'{col}_scaled'] = scaler.fit_transform(train_df[[col]])\n",
        "    test_df[f'{col}_scaled'] = scaler.transform(test_df[[col]])"
      ],
      "execution_count": 715,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbbrE8B9dFcm"
      },
      "source": [
        "deep_arr = train_df[['gender','car','reality','child_num','work_phone','phone','email',\n",
        "          'income_total_scaled','DAYS_BIRTH_scaled','DAYS_EMPLOYED_scaled','family_size_scaled','begin_month_scaled']].values\n",
        "test_deep_arr = test_df[['gender','car','reality','child_num','work_phone','phone','email',\n",
        "          'income_total_scaled','DAYS_BIRTH_scaled','DAYS_EMPLOYED_scaled','family_size_scaled','begin_month_scaled']].values"
      ],
      "execution_count": 716,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_82ulDmpixmi"
      },
      "source": [
        "deep_arr = np.concatenate((deep_arr,emb_arr),axis=1)\n",
        "test_deep_arr = np.concatenate((test_deep_arr,test_emb_arr),axis=1)"
      ],
      "execution_count": 717,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG0RMtfcmlHD",
        "outputId": "22e1b64c-9658-4ec9-edf3-fd7921699e2d"
      },
      "source": [
        "deep_arr.shape,wide_arr.shape,test_deep_arr.shape,test_wide_arr.shape,"
      ],
      "execution_count": 718,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((26457, 37), (26457, 1891), (10000, 37), (10000, 1891))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 718
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHlJsKlnrJqR"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(((np.concatenate((deep_arr,wide_arr),axis=1)),pd.get_dummies(train_df['credit'].astype(np.int32)).values)).shuffle(26457)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(np.concatenate((test_deep_arr,test_wide_arr),axis=1)).batch(256)"
      ],
      "execution_count": 734,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJoQr3nita1S"
      },
      "source": [
        "train_dataset, test_dataset = dataset.take(int(26457*0.9)).batch(256), dataset.skip(int(26457*0.9)).batch(256)"
      ],
      "execution_count": 725,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ45ZdlSjwXH"
      },
      "source": [
        "inputs = keras.Input(shape=(deep_arr.shape[1]+wide_arr.shape[1]))\n",
        "deep,wide = Lambda( lambda x: tf.split(x,num_or_size_splits=[deep_arr.shape[1],wide_arr.shape[1]],axis=1))(inputs)\n",
        "\n",
        "deep = layers.BatchNormalization()(deep)\n",
        "deep = layers.Dense(32,activation='relu')(deep)\n",
        "deep = layers.Dense(12,activation='relu')(deep)\n",
        "deep = layers.Dense(3,activation='relu')(deep)\n",
        "\n",
        "\n",
        "wide = layers.BatchNormalization()(wide)\n",
        "wide = layers.Dense(3,activation='relu')(wide)\n",
        "\n",
        "\n",
        "x = layers.Multiply()([deep,wide])\n",
        "outputs = layers.Dense(3,activation='softmax')(x)"
      ],
      "execution_count": 726,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM31zfW0qO0K",
        "outputId": "211c0bd7-7f27-49ae-e2c8-f9e17068749c"
      },
      "source": [
        "model = keras.Model(inputs, outputs, name=\"wide_deep_model\")\n",
        "model.summary()"
      ],
      "execution_count": 727,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"wide_deep_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_55 (InputLayer)           [(None, 1928)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_56 (Lambda)              [(None, 37), (None,  0           input_55[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 37)           148         lambda_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_204 (Dense)               (None, 32)           1216        batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_205 (Dense)               (None, 12)           396         dense_204[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 1891)         7564        lambda_56[0][1]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_206 (Dense)               (None, 3)            39          dense_205[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_207 (Dense)               (None, 3)            5676        batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, 3)            0           dense_206[0][0]                  \n",
            "                                                                 dense_207[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_208 (Dense)               (None, 3)            12          multiply_4[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 15,051\n",
            "Trainable params: 11,195\n",
            "Non-trainable params: 3,856\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUM92zils08N",
        "outputId": "573f36d4-f20a-4f7d-f91d-0149f1d1eda6"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=100,verbose=1)\n",
        "mc = ModelCheckpoint(PATH+'/model/wide_deep.h5', monitor='val_loss', mode='min', save_best_only=True)\n",
        "history = model.fit(train_dataset,\n",
        "                        epochs=1000,\n",
        "                        verbose=1,\n",
        "                    callbacks=[early_stop, mc],\n",
        "                    validation_data=test_dataset\n",
        "                    )"
      ],
      "execution_count": 728,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "94/94 [==============================] - 2s 15ms/step - loss: 1.0186 - val_loss: 0.9139\n",
            "Epoch 2/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8803 - val_loss: 0.8669\n",
            "Epoch 3/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.8679 - val_loss: 0.8642\n",
            "Epoch 4/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8542 - val_loss: 0.8573\n",
            "Epoch 5/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8489 - val_loss: 0.8397\n",
            "Epoch 6/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.8416 - val_loss: 0.8268\n",
            "Epoch 7/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8308 - val_loss: 0.8305\n",
            "Epoch 8/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8378 - val_loss: 0.8250\n",
            "Epoch 9/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8287 - val_loss: 0.8188\n",
            "Epoch 10/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8217 - val_loss: 0.8010\n",
            "Epoch 11/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8137 - val_loss: 0.8023\n",
            "Epoch 12/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8048 - val_loss: 0.7760\n",
            "Epoch 13/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.8046 - val_loss: 0.8150\n",
            "Epoch 14/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7879 - val_loss: 0.7893\n",
            "Epoch 15/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7758 - val_loss: 0.7732\n",
            "Epoch 16/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7785 - val_loss: 0.7600\n",
            "Epoch 17/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7673 - val_loss: 0.7760\n",
            "Epoch 18/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7671 - val_loss: 0.7561\n",
            "Epoch 19/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7729 - val_loss: 0.7696\n",
            "Epoch 20/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7653 - val_loss: 0.7409\n",
            "Epoch 21/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7534 - val_loss: 0.7619\n",
            "Epoch 22/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7634 - val_loss: 0.7277\n",
            "Epoch 23/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7587 - val_loss: 0.7560\n",
            "Epoch 24/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7626 - val_loss: 0.7194\n",
            "Epoch 25/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7596 - val_loss: 0.7498\n",
            "Epoch 26/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7611 - val_loss: 0.7363\n",
            "Epoch 27/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7495 - val_loss: 0.7378\n",
            "Epoch 28/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7596 - val_loss: 0.7526\n",
            "Epoch 29/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7547 - val_loss: 0.7364\n",
            "Epoch 30/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7426 - val_loss: 0.6993\n",
            "Epoch 31/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7453 - val_loss: 0.7268\n",
            "Epoch 32/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7432 - val_loss: 0.7291\n",
            "Epoch 33/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7554 - val_loss: 0.7389\n",
            "Epoch 34/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7433 - val_loss: 0.7517\n",
            "Epoch 35/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7422 - val_loss: 0.7196\n",
            "Epoch 36/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7457 - val_loss: 0.7189\n",
            "Epoch 37/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7424 - val_loss: 0.7519\n",
            "Epoch 38/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7424 - val_loss: 0.7354\n",
            "Epoch 39/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7370 - val_loss: 0.7373\n",
            "Epoch 40/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7365 - val_loss: 0.7481\n",
            "Epoch 41/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7447 - val_loss: 0.7277\n",
            "Epoch 42/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7311 - val_loss: 0.7302\n",
            "Epoch 43/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7352 - val_loss: 0.7257\n",
            "Epoch 44/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7461 - val_loss: 0.7203\n",
            "Epoch 45/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7423 - val_loss: 0.7135\n",
            "Epoch 46/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7391 - val_loss: 0.7356\n",
            "Epoch 47/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7325 - val_loss: 0.7073\n",
            "Epoch 48/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7345 - val_loss: 0.7191\n",
            "Epoch 49/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7291 - val_loss: 0.7222\n",
            "Epoch 50/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7278 - val_loss: 0.7180\n",
            "Epoch 51/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7219 - val_loss: 0.7206\n",
            "Epoch 52/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7290 - val_loss: 0.7426\n",
            "Epoch 53/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7400 - val_loss: 0.7053\n",
            "Epoch 54/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7291 - val_loss: 0.7089\n",
            "Epoch 55/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7304 - val_loss: 0.6857\n",
            "Epoch 56/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7316 - val_loss: 0.7305\n",
            "Epoch 57/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7262 - val_loss: 0.7238\n",
            "Epoch 58/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7277 - val_loss: 0.7111\n",
            "Epoch 59/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7244 - val_loss: 0.7385\n",
            "Epoch 60/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7233 - val_loss: 0.7073\n",
            "Epoch 61/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7297 - val_loss: 0.7084\n",
            "Epoch 62/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7280 - val_loss: 0.7173\n",
            "Epoch 63/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7259 - val_loss: 0.7241\n",
            "Epoch 64/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7249 - val_loss: 0.7164\n",
            "Epoch 65/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7366 - val_loss: 0.7181\n",
            "Epoch 66/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7259 - val_loss: 0.7161\n",
            "Epoch 67/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7239 - val_loss: 0.6987\n",
            "Epoch 68/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7290 - val_loss: 0.6955\n",
            "Epoch 69/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7266 - val_loss: 0.7173\n",
            "Epoch 70/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7231 - val_loss: 0.7087\n",
            "Epoch 71/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7304 - val_loss: 0.7219\n",
            "Epoch 72/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7234 - val_loss: 0.6896\n",
            "Epoch 73/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7306 - val_loss: 0.7234\n",
            "Epoch 74/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7148 - val_loss: 0.7365\n",
            "Epoch 75/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7126 - val_loss: 0.7211\n",
            "Epoch 76/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7176 - val_loss: 0.7043\n",
            "Epoch 77/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7178 - val_loss: 0.7085\n",
            "Epoch 78/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7161 - val_loss: 0.7055\n",
            "Epoch 79/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7242 - val_loss: 0.7337\n",
            "Epoch 80/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7277 - val_loss: 0.7243\n",
            "Epoch 81/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7224 - val_loss: 0.7016\n",
            "Epoch 82/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7147 - val_loss: 0.7036\n",
            "Epoch 83/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7231 - val_loss: 0.6859\n",
            "Epoch 84/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7231 - val_loss: 0.6974\n",
            "Epoch 85/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7157 - val_loss: 0.6849\n",
            "Epoch 86/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7190 - val_loss: 0.6924\n",
            "Epoch 87/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7048 - val_loss: 0.6991\n",
            "Epoch 88/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7085 - val_loss: 0.6971\n",
            "Epoch 89/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7176 - val_loss: 0.7071\n",
            "Epoch 90/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7167 - val_loss: 0.7023\n",
            "Epoch 91/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7181 - val_loss: 0.6941\n",
            "Epoch 92/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7266 - val_loss: 0.7040\n",
            "Epoch 93/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7295 - val_loss: 0.7053\n",
            "Epoch 94/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7124 - val_loss: 0.6859\n",
            "Epoch 95/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7211 - val_loss: 0.6996\n",
            "Epoch 96/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7131 - val_loss: 0.6861\n",
            "Epoch 97/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7090 - val_loss: 0.6960\n",
            "Epoch 98/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7238 - val_loss: 0.6947\n",
            "Epoch 99/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7196 - val_loss: 0.7151\n",
            "Epoch 100/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7126 - val_loss: 0.7085\n",
            "Epoch 101/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7208 - val_loss: 0.7003\n",
            "Epoch 102/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7204 - val_loss: 0.7003\n",
            "Epoch 103/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7147 - val_loss: 0.6946\n",
            "Epoch 104/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7155 - val_loss: 0.6682\n",
            "Epoch 105/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7114 - val_loss: 0.6905\n",
            "Epoch 106/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7131 - val_loss: 0.7029\n",
            "Epoch 107/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7041 - val_loss: 0.7111\n",
            "Epoch 108/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7111 - val_loss: 0.7387\n",
            "Epoch 109/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7230 - val_loss: 0.7114\n",
            "Epoch 110/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7083 - val_loss: 0.7009\n",
            "Epoch 111/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7293 - val_loss: 0.7003\n",
            "Epoch 112/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7144 - val_loss: 0.6954\n",
            "Epoch 113/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7123 - val_loss: 0.6789\n",
            "Epoch 114/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7095 - val_loss: 0.7053\n",
            "Epoch 115/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7110 - val_loss: 0.6894\n",
            "Epoch 116/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7181 - val_loss: 0.6794\n",
            "Epoch 117/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7041 - val_loss: 0.6927\n",
            "Epoch 118/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7115 - val_loss: 0.6879\n",
            "Epoch 119/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7295 - val_loss: 0.7179\n",
            "Epoch 120/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7182 - val_loss: 0.7180\n",
            "Epoch 121/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7143 - val_loss: 0.6957\n",
            "Epoch 122/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7084 - val_loss: 0.7038\n",
            "Epoch 123/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7130 - val_loss: 0.7015\n",
            "Epoch 124/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7086 - val_loss: 0.7102\n",
            "Epoch 125/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7090 - val_loss: 0.7163\n",
            "Epoch 126/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7034 - val_loss: 0.6819\n",
            "Epoch 127/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7057 - val_loss: 0.6819\n",
            "Epoch 128/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7095 - val_loss: 0.6924\n",
            "Epoch 129/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7008 - val_loss: 0.7010\n",
            "Epoch 130/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7212 - val_loss: 0.7040\n",
            "Epoch 131/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6996 - val_loss: 0.6958\n",
            "Epoch 132/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7062 - val_loss: 0.7188\n",
            "Epoch 133/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7105 - val_loss: 0.6844\n",
            "Epoch 134/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7080 - val_loss: 0.6826\n",
            "Epoch 135/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7143 - val_loss: 0.7142\n",
            "Epoch 136/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7100 - val_loss: 0.6724\n",
            "Epoch 137/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7139 - val_loss: 0.7034\n",
            "Epoch 138/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6991 - val_loss: 0.6859\n",
            "Epoch 139/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7078 - val_loss: 0.6798\n",
            "Epoch 140/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7044 - val_loss: 0.6991\n",
            "Epoch 141/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7106 - val_loss: 0.7041\n",
            "Epoch 142/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7082 - val_loss: 0.6874\n",
            "Epoch 143/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7049 - val_loss: 0.6855\n",
            "Epoch 144/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6991 - val_loss: 0.6999\n",
            "Epoch 145/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7062 - val_loss: 0.6984\n",
            "Epoch 146/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7033 - val_loss: 0.6923\n",
            "Epoch 147/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7057 - val_loss: 0.6903\n",
            "Epoch 148/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7012 - val_loss: 0.6877\n",
            "Epoch 149/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6983 - val_loss: 0.6848\n",
            "Epoch 150/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7068 - val_loss: 0.6653\n",
            "Epoch 151/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7085 - val_loss: 0.6936\n",
            "Epoch 152/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7087 - val_loss: 0.6881\n",
            "Epoch 153/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6990 - val_loss: 0.6885\n",
            "Epoch 154/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7043 - val_loss: 0.6797\n",
            "Epoch 155/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7128 - val_loss: 0.6665\n",
            "Epoch 156/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7109 - val_loss: 0.6635\n",
            "Epoch 157/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7028 - val_loss: 0.6648\n",
            "Epoch 158/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6960 - val_loss: 0.6895\n",
            "Epoch 159/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7103 - val_loss: 0.6975\n",
            "Epoch 160/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7004 - val_loss: 0.6854\n",
            "Epoch 161/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7049 - val_loss: 0.6955\n",
            "Epoch 162/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6961 - val_loss: 0.7094\n",
            "Epoch 163/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6917 - val_loss: 0.6867\n",
            "Epoch 164/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7011 - val_loss: 0.6823\n",
            "Epoch 165/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7015 - val_loss: 0.6696\n",
            "Epoch 166/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6979 - val_loss: 0.6978\n",
            "Epoch 167/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7151 - val_loss: 0.6874\n",
            "Epoch 168/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7168 - val_loss: 0.6920\n",
            "Epoch 169/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7050 - val_loss: 0.6945\n",
            "Epoch 170/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7021 - val_loss: 0.6984\n",
            "Epoch 171/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7006 - val_loss: 0.7011\n",
            "Epoch 172/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7048 - val_loss: 0.6920\n",
            "Epoch 173/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7276 - val_loss: 0.7068\n",
            "Epoch 174/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7017 - val_loss: 0.6769\n",
            "Epoch 175/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6976 - val_loss: 0.7089\n",
            "Epoch 176/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7052 - val_loss: 0.6958\n",
            "Epoch 177/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6947 - val_loss: 0.6864\n",
            "Epoch 178/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6926 - val_loss: 0.6833\n",
            "Epoch 179/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7104 - val_loss: 0.6743\n",
            "Epoch 180/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7064 - val_loss: 0.6835\n",
            "Epoch 181/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6971 - val_loss: 0.6679\n",
            "Epoch 182/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7017 - val_loss: 0.6937\n",
            "Epoch 183/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7043 - val_loss: 0.6809\n",
            "Epoch 184/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6976 - val_loss: 0.6821\n",
            "Epoch 185/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7007 - val_loss: 0.7078\n",
            "Epoch 186/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7257 - val_loss: 0.7166\n",
            "Epoch 187/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6988 - val_loss: 0.6866\n",
            "Epoch 188/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6995 - val_loss: 0.6905\n",
            "Epoch 189/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6994 - val_loss: 0.6732\n",
            "Epoch 190/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6928 - val_loss: 0.6989\n",
            "Epoch 191/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6976 - val_loss: 0.6447\n",
            "Epoch 192/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6899 - val_loss: 0.7006\n",
            "Epoch 193/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7092 - val_loss: 0.6661\n",
            "Epoch 194/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6999 - val_loss: 0.6770\n",
            "Epoch 195/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6934 - val_loss: 0.6526\n",
            "Epoch 196/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6998 - val_loss: 0.6730\n",
            "Epoch 197/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7078 - val_loss: 0.6858\n",
            "Epoch 198/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7113 - val_loss: 0.6662\n",
            "Epoch 199/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7063 - val_loss: 0.6968\n",
            "Epoch 200/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6961 - val_loss: 0.7071\n",
            "Epoch 201/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7109 - val_loss: 0.6954\n",
            "Epoch 202/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7023 - val_loss: 0.6938\n",
            "Epoch 203/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6933 - val_loss: 0.6542\n",
            "Epoch 204/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7026 - val_loss: 0.6711\n",
            "Epoch 205/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6866 - val_loss: 0.6808\n",
            "Epoch 206/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7028 - val_loss: 0.6807\n",
            "Epoch 207/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7042 - val_loss: 0.6781\n",
            "Epoch 208/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6987 - val_loss: 0.6687\n",
            "Epoch 209/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6984 - val_loss: 0.6728\n",
            "Epoch 210/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6936 - val_loss: 0.6797\n",
            "Epoch 211/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6976 - val_loss: 0.6949\n",
            "Epoch 212/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6896 - val_loss: 0.6700\n",
            "Epoch 213/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6978 - val_loss: 0.6825\n",
            "Epoch 214/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7019 - val_loss: 0.6960\n",
            "Epoch 215/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7018 - val_loss: 0.7038\n",
            "Epoch 216/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6982 - val_loss: 0.6984\n",
            "Epoch 217/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6934 - val_loss: 0.6835\n",
            "Epoch 218/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6889 - val_loss: 0.7009\n",
            "Epoch 219/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7024 - val_loss: 0.6737\n",
            "Epoch 220/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6953 - val_loss: 0.6595\n",
            "Epoch 221/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6993 - val_loss: 0.6706\n",
            "Epoch 222/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6981 - val_loss: 0.6828\n",
            "Epoch 223/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7025 - val_loss: 0.7099\n",
            "Epoch 224/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6943 - val_loss: 0.6885\n",
            "Epoch 225/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6909 - val_loss: 0.6803\n",
            "Epoch 226/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6941 - val_loss: 0.6876\n",
            "Epoch 227/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6979 - val_loss: 0.6886\n",
            "Epoch 228/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6976 - val_loss: 0.6975\n",
            "Epoch 229/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6912 - val_loss: 0.6825\n",
            "Epoch 230/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7021 - val_loss: 0.6803\n",
            "Epoch 231/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7001 - val_loss: 0.6786\n",
            "Epoch 232/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6927 - val_loss: 0.6683\n",
            "Epoch 233/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6977 - val_loss: 0.6856\n",
            "Epoch 234/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6931 - val_loss: 0.6648\n",
            "Epoch 235/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6999 - val_loss: 0.6744\n",
            "Epoch 236/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7119 - val_loss: 0.6927\n",
            "Epoch 237/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7058 - val_loss: 0.6828\n",
            "Epoch 238/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6896 - val_loss: 0.6726\n",
            "Epoch 239/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6929 - val_loss: 0.6692\n",
            "Epoch 240/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7160 - val_loss: 0.6911\n",
            "Epoch 241/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6930 - val_loss: 0.7111\n",
            "Epoch 242/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6990 - val_loss: 0.6733\n",
            "Epoch 243/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6991 - val_loss: 0.6879\n",
            "Epoch 244/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7135 - val_loss: 0.6526\n",
            "Epoch 245/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7001 - val_loss: 0.6787\n",
            "Epoch 246/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6845 - val_loss: 0.6958\n",
            "Epoch 247/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6890 - val_loss: 0.6854\n",
            "Epoch 248/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6981 - val_loss: 0.6917\n",
            "Epoch 249/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6947 - val_loss: 0.6764\n",
            "Epoch 250/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6858 - val_loss: 0.6723\n",
            "Epoch 251/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7070 - val_loss: 0.6983\n",
            "Epoch 252/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6933 - val_loss: 0.6571\n",
            "Epoch 253/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6959 - val_loss: 0.6716\n",
            "Epoch 254/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6921 - val_loss: 0.6987\n",
            "Epoch 255/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6936 - val_loss: 0.6828\n",
            "Epoch 256/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6999 - val_loss: 0.6825\n",
            "Epoch 257/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6851 - val_loss: 0.6910\n",
            "Epoch 258/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6994 - val_loss: 0.6676\n",
            "Epoch 259/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6945 - val_loss: 0.6702\n",
            "Epoch 260/1000\n",
            "94/94 [==============================] - 1s 13ms/step - loss: 0.6951 - val_loss: 0.6891\n",
            "Epoch 261/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6981 - val_loss: 0.6535\n",
            "Epoch 262/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6910 - val_loss: 0.6723\n",
            "Epoch 263/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7023 - val_loss: 0.6635\n",
            "Epoch 264/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6994 - val_loss: 0.6719\n",
            "Epoch 265/1000\n",
            "94/94 [==============================] - 1s 13ms/step - loss: 0.6910 - val_loss: 0.6749\n",
            "Epoch 266/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6956 - val_loss: 0.6494\n",
            "Epoch 267/1000\n",
            "94/94 [==============================] - 1s 13ms/step - loss: 0.6888 - val_loss: 0.6860\n",
            "Epoch 268/1000\n",
            "94/94 [==============================] - 1s 13ms/step - loss: 0.6894 - val_loss: 0.6826\n",
            "Epoch 269/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6936 - val_loss: 0.6782\n",
            "Epoch 270/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6808 - val_loss: 0.6777\n",
            "Epoch 271/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6977 - val_loss: 0.6978\n",
            "Epoch 272/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6954 - val_loss: 0.6569\n",
            "Epoch 273/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6950 - val_loss: 0.6690\n",
            "Epoch 274/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6891 - val_loss: 0.6474\n",
            "Epoch 275/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6873 - val_loss: 0.6894\n",
            "Epoch 276/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7032 - val_loss: 0.6720\n",
            "Epoch 277/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6942 - val_loss: 0.6804\n",
            "Epoch 278/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6988 - val_loss: 0.6967\n",
            "Epoch 279/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7128 - val_loss: 0.6821\n",
            "Epoch 280/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6891 - val_loss: 0.6583\n",
            "Epoch 281/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6849 - val_loss: 0.6896\n",
            "Epoch 282/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.7046 - val_loss: 0.6784\n",
            "Epoch 283/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6944 - val_loss: 0.6648\n",
            "Epoch 284/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6932 - val_loss: 0.6930\n",
            "Epoch 285/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6879 - val_loss: 0.6594\n",
            "Epoch 286/1000\n",
            "94/94 [==============================] - 1s 11ms/step - loss: 0.6995 - val_loss: 0.6654\n",
            "Epoch 287/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6945 - val_loss: 0.6946\n",
            "Epoch 288/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.6853 - val_loss: 0.6704\n",
            "Epoch 289/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7089 - val_loss: 0.6929\n",
            "Epoch 290/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7141 - val_loss: 0.6740\n",
            "Epoch 291/1000\n",
            "94/94 [==============================] - 1s 12ms/step - loss: 0.7035 - val_loss: 0.6905\n",
            "Epoch 00291: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "M1tC1qcYtrkk",
        "outputId": "66efe6ae-424f-4517-e81d-40dae4db34fb"
      },
      "source": [
        "plt.plot(history.history['val_loss'])"
      ],
      "execution_count": 729,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcb720d4c50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 729
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzd20AxsTPqm"
      },
      "source": [
        "saved_model = tf.keras.models.load_model(PATH+'/model/wide_deep.h5')"
      ],
      "execution_count": 730,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yB1lZlfXRNN"
      },
      "source": [
        "submission = pd.read_csv(PATH+'/dataset/sample_submission.csv')"
      ],
      "execution_count": 731,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1VThrg4XeD_"
      },
      "source": [
        "submission.iloc[:,1:] = saved_model.predict(test_dataset)"
      ],
      "execution_count": 735,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "glBD0mmNaN8F",
        "outputId": "e9af347a-7844-4359-fb16-3acbed208aa3"
      },
      "source": [
        "submission.head(20)"
      ],
      "execution_count": 736,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26457</td>\n",
              "      <td>5.802666e-02</td>\n",
              "      <td>8.018202e-02</td>\n",
              "      <td>0.861791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26458</td>\n",
              "      <td>4.024419e-02</td>\n",
              "      <td>3.384508e-02</td>\n",
              "      <td>0.925911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26459</td>\n",
              "      <td>1.405869e-01</td>\n",
              "      <td>1.648751e-01</td>\n",
              "      <td>0.694538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26460</td>\n",
              "      <td>1.296501e-01</td>\n",
              "      <td>1.374746e-01</td>\n",
              "      <td>0.732875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26461</td>\n",
              "      <td>2.760883e-02</td>\n",
              "      <td>1.055642e-01</td>\n",
              "      <td>0.866827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>26462</td>\n",
              "      <td>5.673752e-02</td>\n",
              "      <td>1.077523e-01</td>\n",
              "      <td>0.835510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26463</td>\n",
              "      <td>3.536673e-01</td>\n",
              "      <td>6.455706e-01</td>\n",
              "      <td>0.000762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>26464</td>\n",
              "      <td>1.104691e-01</td>\n",
              "      <td>1.948309e-01</td>\n",
              "      <td>0.694700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>26465</td>\n",
              "      <td>7.400550e-02</td>\n",
              "      <td>2.069490e-01</td>\n",
              "      <td>0.719045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>26466</td>\n",
              "      <td>2.590980e-01</td>\n",
              "      <td>3.224090e-01</td>\n",
              "      <td>0.418493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>26467</td>\n",
              "      <td>9.462837e-02</td>\n",
              "      <td>1.307259e-01</td>\n",
              "      <td>0.774646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>26468</td>\n",
              "      <td>8.245912e-02</td>\n",
              "      <td>1.036331e-01</td>\n",
              "      <td>0.813908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>26469</td>\n",
              "      <td>4.303205e-01</td>\n",
              "      <td>5.432333e-01</td>\n",
              "      <td>0.026446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>26470</td>\n",
              "      <td>9.987484e-02</td>\n",
              "      <td>1.167032e-01</td>\n",
              "      <td>0.783422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>26471</td>\n",
              "      <td>1.016738e-01</td>\n",
              "      <td>2.371932e-01</td>\n",
              "      <td>0.661133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>26472</td>\n",
              "      <td>7.491301e-02</td>\n",
              "      <td>7.468134e-02</td>\n",
              "      <td>0.850406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>26473</td>\n",
              "      <td>1.364940e-01</td>\n",
              "      <td>2.662933e-01</td>\n",
              "      <td>0.597213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>26474</td>\n",
              "      <td>3.243243e-01</td>\n",
              "      <td>6.754929e-01</td>\n",
              "      <td>0.000183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>26475</td>\n",
              "      <td>3.489848e-01</td>\n",
              "      <td>3.346305e-01</td>\n",
              "      <td>0.316385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>26476</td>\n",
              "      <td>1.048041e-12</td>\n",
              "      <td>8.766863e-14</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index             0             1         2\n",
              "0   26457  5.802666e-02  8.018202e-02  0.861791\n",
              "1   26458  4.024419e-02  3.384508e-02  0.925911\n",
              "2   26459  1.405869e-01  1.648751e-01  0.694538\n",
              "3   26460  1.296501e-01  1.374746e-01  0.732875\n",
              "4   26461  2.760883e-02  1.055642e-01  0.866827\n",
              "5   26462  5.673752e-02  1.077523e-01  0.835510\n",
              "6   26463  3.536673e-01  6.455706e-01  0.000762\n",
              "7   26464  1.104691e-01  1.948309e-01  0.694700\n",
              "8   26465  7.400550e-02  2.069490e-01  0.719045\n",
              "9   26466  2.590980e-01  3.224090e-01  0.418493\n",
              "10  26467  9.462837e-02  1.307259e-01  0.774646\n",
              "11  26468  8.245912e-02  1.036331e-01  0.813908\n",
              "12  26469  4.303205e-01  5.432333e-01  0.026446\n",
              "13  26470  9.987484e-02  1.167032e-01  0.783422\n",
              "14  26471  1.016738e-01  2.371932e-01  0.661133\n",
              "15  26472  7.491301e-02  7.468134e-02  0.850406\n",
              "16  26473  1.364940e-01  2.662933e-01  0.597213\n",
              "17  26474  3.243243e-01  6.754929e-01  0.000183\n",
              "18  26475  3.489848e-01  3.346305e-01  0.316385\n",
              "19  26476  1.048041e-12  8.766863e-14  1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 736
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytw_oizaXndc"
      },
      "source": [
        "submission.to_csv(PATH+'/result/wide-deep3.csv',index=False)"
      ],
      "execution_count": 737,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeBsXRMRX2J5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}