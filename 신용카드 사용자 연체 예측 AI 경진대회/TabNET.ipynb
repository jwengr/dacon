{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TabNET.ipynb",
      "provenance": [],
      "mount_file_id": "1uvYIo3rjnU18fQUnnjhYmcDl7rUQcuq5",
      "authorship_tag": "ABX9TyM2Uf5psUB+/OuLTuxo294C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwengr/dacon/blob/main/%EC%8B%A0%EC%9A%A9%EC%B9%B4%EB%93%9C%20%EC%82%AC%EC%9A%A9%EC%9E%90%20%EC%97%B0%EC%B2%B4%20%EC%98%88%EC%B8%A1%20AI%20%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C/TabNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2_SCHCoTpEt",
        "outputId": "c089b0a5-14ed-479b-aabd-97f9fa358689"
      },
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading https://files.pythonhosted.org/packages/94/e5/2a808d611a5d44e3c997c0d07362c04a56c70002208e00aec9eee3d923b5/pytorch_tabnet-3.1.1-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.41.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.19.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0g1ecbRQ0W5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from pytorch_tabnet.multitask import TabNetMultiTaskClassifier\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "from pytorch_tabnet.metrics import Metric\n",
        "from sklearn.model_selection import StratifiedKFold ,train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMr6RYBMQl6E"
      },
      "source": [
        "PATH = 'drive/My Drive/dacon/credit'"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOWPI1z1QyCC"
      },
      "source": [
        "train = pd.read_csv(PATH+'/dataset/train.csv').drop(['index','FLAG_MOBIL'],axis=1)\n",
        "test = pd.read_csv(PATH+'/dataset/test.csv').drop(['index','FLAG_MOBIL'],axis=1)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HEwC4cIczl7"
      },
      "source": [
        "train['occyp_type'].fillna('one two three',inplace=True)\n",
        "test['occyp_type'].fillna('one two three',inplace=True)\n",
        "train['begin_months'] = train['begin_month'].values%12\n",
        "test['begin_months'] = test['begin_month'].values%12\n",
        "train['not_employed'] = (train['DAYS_EMPLOYED']>0).astype(np.int32)\n",
        "test['not_employed'] = (test['DAYS_EMPLOYED']>0).astype(np.int32)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aquXeYgAVkgu",
        "outputId": "257bdb22-82dc-4172-9193-50054df08ee2"
      },
      "source": [
        "train_df,val_df = train_test_split(train,test_size=0.2,stratify=train['credit'])\n",
        "test_df = test.copy()\n",
        "\n",
        "le = LabelEncoder()\n",
        "for col in ['gender','car','reality','work_phone','phone','email']:\n",
        "    le.fit(train[[col]])\n",
        "    train_df[[col]] = le.transform(train_df[[col]]).astype(np.int32)\n",
        "    val_df[[col]] = le.transform(val_df[[col]]).astype(np.int32)\n",
        "    test_df[[col]] = le.transform(test_df[[col]]).astype(np.int32)\n",
        "\n",
        "categorical_columns = ['income_type','edu_type','family_type','house_type','occyp_type','begin_months']\n",
        "categorical_dims = dict()\n",
        "for col in categorical_columns:\n",
        "    le.fit(train[[col]])\n",
        "    train_df[[col]] = le.fit_transform(train_df[[col]])\n",
        "    val_df[[col]] = le.fit_transform(val_df[[col]])\n",
        "    test_df[[col]] = le.fit_transform(test_df[[col]])\n",
        "    categorical_dims[col] = len(le.classes_)\n",
        "\n",
        "features = train_df.drop('credit',axis=1).columns\n",
        "cat_idxs = [i for i, f in enumerate(features) if f in categorical_columns]\n",
        "cat_dims = [ categorical_dims[f] for f in features if f in categorical_columns]\n",
        "\n",
        "X_train = train_df.drop('credit',axis=1).values\n",
        "y_train = train_df['credit'].values\n",
        "\n",
        "X_valid = val_df.drop('credit',axis=1).values\n",
        "y_valid = val_df['credit'].values\n",
        "\n",
        "X_test = test_df.values\n",
        "\n",
        "clf = TabNetClassifier(\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=2,\n",
        "    n_d=8,n_a=8,n_steps=3,gamma=1.3,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"swa_lr\":0.01},\n",
        "    scheduler_fn=torch.optim.swa_utils.SWALR,\n",
        "    mask_type='entmax',\n",
        "    device_name = 'cuda'\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    eval_metric=['logloss'],\n",
        "    patience=50,\n",
        "    num_workers=0,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        ")\n",
        "\n"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Device used : cuda\n",
            "epoch 0  | loss: 0.94476 | val_0_logloss: 1.12451 |  0:00:01s\n",
            "epoch 1  | loss: 0.87917 | val_0_logloss: 0.88291 |  0:00:02s\n",
            "epoch 2  | loss: 0.86701 | val_0_logloss: 0.88113 |  0:00:04s\n",
            "epoch 3  | loss: 0.85164 | val_0_logloss: 0.86952 |  0:00:05s\n",
            "epoch 4  | loss: 0.83563 | val_0_logloss: 0.8746  |  0:00:07s\n",
            "epoch 5  | loss: 0.82046 | val_0_logloss: 0.85458 |  0:00:08s\n",
            "epoch 6  | loss: 0.81561 | val_0_logloss: 0.82897 |  0:00:10s\n",
            "epoch 7  | loss: 0.81452 | val_0_logloss: 0.81516 |  0:00:11s\n",
            "epoch 8  | loss: 0.81232 | val_0_logloss: 0.81246 |  0:00:13s\n",
            "epoch 9  | loss: 0.81064 | val_0_logloss: 0.81154 |  0:00:14s\n",
            "epoch 10 | loss: 0.81026 | val_0_logloss: 0.80597 |  0:00:15s\n",
            "epoch 11 | loss: 0.81173 | val_0_logloss: 0.80401 |  0:00:17s\n",
            "epoch 12 | loss: 0.81061 | val_0_logloss: 0.807   |  0:00:19s\n",
            "epoch 13 | loss: 0.80894 | val_0_logloss: 0.80374 |  0:00:20s\n",
            "epoch 14 | loss: 0.80761 | val_0_logloss: 0.80383 |  0:00:22s\n",
            "epoch 15 | loss: 0.80985 | val_0_logloss: 0.80506 |  0:00:23s\n",
            "epoch 16 | loss: 0.80782 | val_0_logloss: 0.80342 |  0:00:24s\n",
            "epoch 17 | loss: 0.80802 | val_0_logloss: 0.80484 |  0:00:26s\n",
            "epoch 18 | loss: 0.80778 | val_0_logloss: 0.80401 |  0:00:27s\n",
            "epoch 19 | loss: 0.80753 | val_0_logloss: 0.80258 |  0:00:29s\n",
            "epoch 20 | loss: 0.80885 | val_0_logloss: 0.80437 |  0:00:30s\n",
            "epoch 21 | loss: 0.80835 | val_0_logloss: 0.80459 |  0:00:32s\n",
            "epoch 22 | loss: 0.80645 | val_0_logloss: 0.80336 |  0:00:33s\n",
            "epoch 23 | loss: 0.80527 | val_0_logloss: 0.80498 |  0:00:35s\n",
            "epoch 24 | loss: 0.80513 | val_0_logloss: 0.80452 |  0:00:36s\n",
            "epoch 25 | loss: 0.80604 | val_0_logloss: 0.80394 |  0:00:38s\n",
            "epoch 26 | loss: 0.80548 | val_0_logloss: 0.80556 |  0:00:39s\n",
            "epoch 27 | loss: 0.80413 | val_0_logloss: 0.80467 |  0:00:41s\n",
            "epoch 28 | loss: 0.80314 | val_0_logloss: 0.80422 |  0:00:42s\n",
            "epoch 29 | loss: 0.80235 | val_0_logloss: 0.80347 |  0:00:44s\n",
            "epoch 30 | loss: 0.80211 | val_0_logloss: 0.8031  |  0:00:45s\n",
            "epoch 31 | loss: 0.80257 | val_0_logloss: 0.80338 |  0:00:46s\n",
            "epoch 32 | loss: 0.8017  | val_0_logloss: 0.80367 |  0:00:48s\n",
            "epoch 33 | loss: 0.80082 | val_0_logloss: 0.80091 |  0:00:49s\n",
            "epoch 34 | loss: 0.79975 | val_0_logloss: 0.80224 |  0:00:51s\n",
            "epoch 35 | loss: 0.80067 | val_0_logloss: 0.80298 |  0:00:53s\n",
            "epoch 36 | loss: 0.7988  | val_0_logloss: 0.80288 |  0:00:54s\n",
            "epoch 37 | loss: 0.79841 | val_0_logloss: 0.8028  |  0:00:55s\n",
            "epoch 38 | loss: 0.79676 | val_0_logloss: 0.80428 |  0:00:57s\n",
            "epoch 39 | loss: 0.79726 | val_0_logloss: 0.80464 |  0:00:58s\n",
            "epoch 40 | loss: 0.79765 | val_0_logloss: 0.80384 |  0:01:00s\n",
            "epoch 41 | loss: 0.79657 | val_0_logloss: 0.8047  |  0:01:01s\n",
            "epoch 42 | loss: 0.7964  | val_0_logloss: 0.80259 |  0:01:03s\n",
            "epoch 43 | loss: 0.79424 | val_0_logloss: 0.80508 |  0:01:04s\n",
            "epoch 44 | loss: 0.79462 | val_0_logloss: 0.80478 |  0:01:06s\n",
            "epoch 45 | loss: 0.79318 | val_0_logloss: 0.80632 |  0:01:07s\n",
            "epoch 46 | loss: 0.79158 | val_0_logloss: 0.80566 |  0:01:08s\n",
            "epoch 47 | loss: 0.79165 | val_0_logloss: 0.80356 |  0:01:10s\n",
            "epoch 48 | loss: 0.79072 | val_0_logloss: 0.80389 |  0:01:11s\n",
            "epoch 49 | loss: 0.78914 | val_0_logloss: 0.80176 |  0:01:13s\n",
            "epoch 50 | loss: 0.78767 | val_0_logloss: 0.8047  |  0:01:14s\n",
            "epoch 51 | loss: 0.78904 | val_0_logloss: 0.80542 |  0:01:16s\n",
            "epoch 52 | loss: 0.7878  | val_0_logloss: 0.80358 |  0:01:17s\n",
            "epoch 53 | loss: 0.78693 | val_0_logloss: 0.80352 |  0:01:19s\n",
            "epoch 54 | loss: 0.78668 | val_0_logloss: 0.80415 |  0:01:20s\n",
            "epoch 55 | loss: 0.78434 | val_0_logloss: 0.80447 |  0:01:22s\n",
            "epoch 56 | loss: 0.78501 | val_0_logloss: 0.80711 |  0:01:23s\n",
            "epoch 57 | loss: 0.78119 | val_0_logloss: 0.8055  |  0:01:24s\n",
            "epoch 58 | loss: 0.78144 | val_0_logloss: 0.80883 |  0:01:26s\n",
            "epoch 59 | loss: 0.77998 | val_0_logloss: 0.80724 |  0:01:27s\n",
            "epoch 60 | loss: 0.78021 | val_0_logloss: 0.81036 |  0:01:29s\n",
            "epoch 61 | loss: 0.77856 | val_0_logloss: 0.80834 |  0:01:30s\n",
            "epoch 62 | loss: 0.77799 | val_0_logloss: 0.80936 |  0:01:32s\n",
            "epoch 63 | loss: 0.77859 | val_0_logloss: 0.80695 |  0:01:33s\n",
            "epoch 64 | loss: 0.77476 | val_0_logloss: 0.80484 |  0:01:35s\n",
            "epoch 65 | loss: 0.77426 | val_0_logloss: 0.80689 |  0:01:36s\n",
            "epoch 66 | loss: 0.77512 | val_0_logloss: 0.80773 |  0:01:38s\n",
            "epoch 67 | loss: 0.77296 | val_0_logloss: 0.80488 |  0:01:39s\n",
            "epoch 68 | loss: 0.77305 | val_0_logloss: 0.80667 |  0:01:41s\n",
            "epoch 69 | loss: 0.77457 | val_0_logloss: 0.80371 |  0:01:42s\n",
            "epoch 70 | loss: 0.76808 | val_0_logloss: 0.80418 |  0:01:44s\n",
            "epoch 71 | loss: 0.77053 | val_0_logloss: 0.8045  |  0:01:45s\n",
            "epoch 72 | loss: 0.7711  | val_0_logloss: 0.80619 |  0:01:46s\n",
            "epoch 73 | loss: 0.77281 | val_0_logloss: 0.80522 |  0:01:48s\n",
            "epoch 74 | loss: 0.7698  | val_0_logloss: 0.80655 |  0:01:49s\n",
            "epoch 75 | loss: 0.76824 | val_0_logloss: 0.80758 |  0:01:51s\n",
            "epoch 76 | loss: 0.77052 | val_0_logloss: 0.8118  |  0:01:52s\n",
            "epoch 77 | loss: 0.77112 | val_0_logloss: 0.81018 |  0:01:53s\n",
            "epoch 78 | loss: 0.77101 | val_0_logloss: 0.80929 |  0:01:55s\n",
            "epoch 79 | loss: 0.76746 | val_0_logloss: 0.80717 |  0:01:56s\n",
            "epoch 80 | loss: 0.76843 | val_0_logloss: 0.80457 |  0:01:58s\n",
            "epoch 81 | loss: 0.76339 | val_0_logloss: 0.80813 |  0:01:59s\n",
            "epoch 82 | loss: 0.75949 | val_0_logloss: 0.80693 |  0:02:01s\n",
            "epoch 83 | loss: 0.76272 | val_0_logloss: 0.81194 |  0:02:02s\n",
            "\n",
            "Early stopping occurred at epoch 83 with best_epoch = 33 and best_val_0_logloss = 0.80091\n",
            "Best weights from best epoch are automatically used!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX8KdTpOCD13"
      },
      "source": [
        "submission = pd.read_csv(PATH+'/dataset/sample_submission.csv')\n",
        "submission.iloc[:,1:] = clf.predict_proba(X_test)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "XAp2BNJDCPzj",
        "outputId": "5107b2be-56ee-48ff-b46d-168adf5468fd"
      },
      "source": [
        "submission.head(20)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26457</td>\n",
              "      <td>0.156140</td>\n",
              "      <td>0.213741</td>\n",
              "      <td>0.630119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26458</td>\n",
              "      <td>0.083042</td>\n",
              "      <td>0.146327</td>\n",
              "      <td>0.770632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26459</td>\n",
              "      <td>0.159687</td>\n",
              "      <td>0.185087</td>\n",
              "      <td>0.655226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26460</td>\n",
              "      <td>0.148458</td>\n",
              "      <td>0.208375</td>\n",
              "      <td>0.643166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26461</td>\n",
              "      <td>0.139848</td>\n",
              "      <td>0.249127</td>\n",
              "      <td>0.611024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>26462</td>\n",
              "      <td>0.147482</td>\n",
              "      <td>0.254653</td>\n",
              "      <td>0.597865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>26463</td>\n",
              "      <td>0.510827</td>\n",
              "      <td>0.329742</td>\n",
              "      <td>0.159431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>26464</td>\n",
              "      <td>0.123184</td>\n",
              "      <td>0.193046</td>\n",
              "      <td>0.683770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>26465</td>\n",
              "      <td>0.119793</td>\n",
              "      <td>0.226275</td>\n",
              "      <td>0.653932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>26466</td>\n",
              "      <td>0.114807</td>\n",
              "      <td>0.238929</td>\n",
              "      <td>0.646265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>26467</td>\n",
              "      <td>0.139404</td>\n",
              "      <td>0.230042</td>\n",
              "      <td>0.630555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>26468</td>\n",
              "      <td>0.127310</td>\n",
              "      <td>0.207296</td>\n",
              "      <td>0.665393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>26469</td>\n",
              "      <td>0.112432</td>\n",
              "      <td>0.155123</td>\n",
              "      <td>0.732445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>26470</td>\n",
              "      <td>0.099505</td>\n",
              "      <td>0.169077</td>\n",
              "      <td>0.731418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>26471</td>\n",
              "      <td>0.136786</td>\n",
              "      <td>0.210126</td>\n",
              "      <td>0.653088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>26472</td>\n",
              "      <td>0.140436</td>\n",
              "      <td>0.230153</td>\n",
              "      <td>0.629411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>26473</td>\n",
              "      <td>0.106407</td>\n",
              "      <td>0.187569</td>\n",
              "      <td>0.706024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>26474</td>\n",
              "      <td>0.203504</td>\n",
              "      <td>0.794157</td>\n",
              "      <td>0.002339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>26475</td>\n",
              "      <td>0.126479</td>\n",
              "      <td>0.178337</td>\n",
              "      <td>0.695184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>26476</td>\n",
              "      <td>0.092317</td>\n",
              "      <td>0.148381</td>\n",
              "      <td>0.759302</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    index         0         1         2\n",
              "0   26457  0.156140  0.213741  0.630119\n",
              "1   26458  0.083042  0.146327  0.770632\n",
              "2   26459  0.159687  0.185087  0.655226\n",
              "3   26460  0.148458  0.208375  0.643166\n",
              "4   26461  0.139848  0.249127  0.611024\n",
              "5   26462  0.147482  0.254653  0.597865\n",
              "6   26463  0.510827  0.329742  0.159431\n",
              "7   26464  0.123184  0.193046  0.683770\n",
              "8   26465  0.119793  0.226275  0.653932\n",
              "9   26466  0.114807  0.238929  0.646265\n",
              "10  26467  0.139404  0.230042  0.630555\n",
              "11  26468  0.127310  0.207296  0.665393\n",
              "12  26469  0.112432  0.155123  0.732445\n",
              "13  26470  0.099505  0.169077  0.731418\n",
              "14  26471  0.136786  0.210126  0.653088\n",
              "15  26472  0.140436  0.230153  0.629411\n",
              "16  26473  0.106407  0.187569  0.706024\n",
              "17  26474  0.203504  0.794157  0.002339\n",
              "18  26475  0.126479  0.178337  0.695184\n",
              "19  26476  0.092317  0.148381  0.759302"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bVkCSHhCTiO"
      },
      "source": [
        "submission.to_csv(PATH+'/result/tabnet1.csv',index=False)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vieazPMCWpC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}